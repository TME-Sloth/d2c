const n=`> **摘要**：本文是一篇技术分享 + 踩坑历程。篇幅不短，建议大家先去冲杯咖啡 ☕️，找个舒服的姿势，看看我们是如何给 AI 转码 加上“暂停键”，解决前端还原痛点的。

## 1. 写在前面：AI 写代码很快，但为什么我们还在加班？

现在的 AI 模型进化速度简直离谱，写个贪吃蛇、画个 \`landing page\` 只需要十几秒。但作为前端开发，咱们心里都清楚：**写 Demo** 和 **还原生产级 UI** 完全是两个维度的游戏。

后端兄弟可以通过语言描述业务关系生成代码，但前端不行。我们得盯着像素眼，既要还原设计语言，又要保住交互逻辑，还得在视觉上和设计稿一模一样。

市面上其实已经有不少 AI 转码工具了，但说实话，一直没出现真正的银弹。为啥？因为痛点太痛了：

1. **UI还原度低**：把整张设计稿丢给 AI，\`Token\` 稍微一多，AI 就开始幻觉了，布局关系乱飞。
2. **一次性代码**：AI 生成的代码压根不认识你项目里的组件，全是原生的元素和硬编码的样式，复用性为零。
3. **迭代更新困难**：代码生成容易，二次修改难。设计师改了个颜色，AI 却把整个文件重写了一遍，你刚写的点击逻辑全没了。
4. **细节无法追加**：交互逻辑（比如点击后的动效、层级变化）很难在转码时一次性描述清楚。
5. **新框架适配难**：昨天用 \`React\`，今天切 \`Vue3\`，明天搞自研框架，AI 一脸懵逼，每次都得写几千字的 \`Prompt\` 放到上下文里。

问题很多，但我们决定先解决最“扎心”的。我们不想让 AI 只是生成一堆这就废弃的“垃圾代码”，我们要的是**可维护、可复用的生产代码**。

---

## 2. Sloth MCP 的解题思路：给 AI 流程按个暂停键

经过大量实践，我们发现了一个朴素的真理：输入给模型的设计稿区块越小、语义越单一，生成的代码质量就越高。所以，我们的核心方案就是——**分块转码 (Chunking)** + **人工介入 (Human-in-the-loop)**。

但是，怎么切？怎么介入？我们的架构选择是：**AI IDE + MCP 工具 + 自研执行拦截器**。

也就是 \`Sloth MCP\` 插件。https://www.npmjs.com/package/sloth-d2c-mcp

### 核心黑科技：执行拦截器 -> AI 导演模式

传统的 MCP (Model Context Protocol) 调用通常是个黑盒子，结果错了只能重来。\`Sloth MCP\` 不一样。我们在 IDE 发起转码指令后，利用 \`await\` 挂起 MCP 请求，强行按下了“暂停键”，同时弹出一个本地的 **Web 交互工作台**。用户可以在 AI 生成代码之前，进行关键的干预。

![转码架构图](https://cos-yyr.tencentmusic.com/sloth/d2c/01.png)

如上图所示，整个链路本质上是一次被人为暂停的异步函数调用。我们将整个过程拆解为四个核心阶段：

**1. 触发与挂起**

**1.1 链路启动 (Step 1-2)：** 当设计稿数据从 Figma 推送至 Sloth MCP 后，AI Coding 环境（IDE）接收到指令，开始解析 \`Prompt\` 并尝试调用 MCP 工具链 (#tools)。

**1.2 执行冻结 (Step 3)：** 关键的一步来了。\`MCP Server\` 接收到调用请求后，并不会立即执行转码逻辑，而是主动挂起进程 (Suspend Process)。这就好比你在看电影时按下了暂停键，AI 的执行流在这里被冻结，等待下一步指令。

---

**2. 唤起交互环境**

**2.1 启动服务 (Step 4)：** 在挂起的同时，\`MCP Server\` 会在本地瞬间启动一个轻量级的 Web Server。

**2.2 可视化拦截 (Step 5)：** 这个\`Web Server\` 会分别向浏览器或 VSCode 插件端推送一个拦截页面。这就是我们所说的“可视化工作台”。在这个页面中，设计稿数据被渲染出来，开发者拥有了上帝视角。

---

**3. 人工介入与编排**

**3.1 注入意图 (Step 5-6)：** 在这个中间态中，开发者进行“配置、框选、提示词补充”。你做的每一个拖拽、写的每一句局部 Prompt，实际上都是在为即将恢复运行的 AI “修补上下文”。

**3.2 数据回传 (Step 6)：** 当你点击“确认生成”时，这些经过人工增强的配置数据会被打包，提交回 Web Server。

---

**4. 进程释放与执行**

**4.1 释放进程 (Step 7)：** Web Server 接收到数据后，通知 MCP Server：“数据准备好了，继续跑吧！”。挂起的进程被释放。

**4.2 采样与生成 (Step 8)：** 此时的 AI 不再是盲目猜测，而是带着你刚才注入的精准上下文，开始**“AI 采样执行”。它会严格按照你的分块策略进行分块 (Chunking)，对代码进行聚合 (Aggregation)，最后写入 (Writing)** 到你的工程文件中。

整体像不像一个智能的agent在预设的编排分工转码任务。这套架构的最大价值在于打破了 AI 生成的“盲盒效应”。传统的 AI 转码是 Input -> AI -> Output，中间错了只能重来。 \`Sloth MCP\` 的架构是 Input -> AI (Pause) -> Human Correction -> AI (Resume) -> Output。

我们利用 MCP 协议的灵活性，在 AI 的推理流中强行插入了一个人工决策层，用极低的成本实现了代码生成质量的指数级提升。

---

## 3. 核心功能：\`Sloth MCP\` 在“拦截”期间都能干嘛？

在这个交互工作台里，我们集成了六大核心能力，逐个击破前面的痛点：

### 1. 手动分区（解决 Token 限制与逻辑混乱）

我们在工作台中会拿到Figma插件通过本地 \`MCP Node\`推送过来的转码数据，进行设计稿渲染预览。（这里用户就能看到初步的页面还原度）。用户只需在预览页简单的拖拽框选，就可以微调或重新划分设计稿的逻辑区域。每个分区，AI 都会单独生成对应的模块代码，互不干扰，精准度打满了。

这里为什么没有使用视觉或者多模态的自动分区？因为我们发现，自动分区的准确率并不高，尤其是对于复杂页面，AI 很难理解设计意图。人工分区虽然多了一步操作，但能确保每个模块的语义清晰，生成的代码质量更高。

> **[插入视频/GIF：展示用户在预览图上拖拽画框，调整分区的过程]**

### 2. 技术栈灵活适配（不被框架绑架）

不管是 React、Vue，还是公司内部那套祖传的自研框架，\`Sloth MCP\` 都能适配。

我们在本地预存了主流技术栈模板，同时也支持自定义 Prompt。你可以把团队的 ESLint 规则、代码风格喂给它。准备得越充分，AI 吐出来的代码就越像你亲自写的。但是坦白的说，转码的效果，还是很大程度上依赖于模型本身的能力和提示词的设计水平。

> **[插入图片：技术栈选择下拉框，以及自定义 Prompt 的配置界面]**

### 3. 组件映射（拒绝重复造轮子！）

**这是最硬核的功能。** 当你圈选设计稿上的一个卡片时，可以选择“映射到已有组件”。\`Sloth MCP\` 会读取你本地的组件文件（基于 AST 解析或大模型阅读），理解它的 \`Props\` 定义。

同时为了兼容不同语言框架的设计，我们也让模型生成了这个组件的导入代码的方式。
接下来的生成中，AI 不会再傻傻地写一堆 \`div\`，而是直接生成 \`<UserCard name="xxx" avatar="xxx" />\`。

> **[插入视频：展示将设计稿元素映射到本地代码组件的流程]**

### 4. 模块标记与视觉记忆（越用越聪明）

有些模块虽然不是通用组件，但在当前项目里反复出现。你可以把它标记为“组件区域”。Sloth 会利用视觉图形特征记住它的样子。

下次在其他页面遇到类似设计，它会跳出来说：“嘿，这个模块你之前写过！”并自动复用之前的逻辑。

### 5. 局部提示词（交互逻辑不再丢失）

设计图是死的，交互是活的。你可以在分块上添加“局部 Prompt”，比如“这个按钮点击后要防抖并提交表单”。

AI 在生成该区块代码时，会把这段逻辑通过注释或函数实现出来。你甚至可以 @ 本地的方法名，让它自动串联逻辑。

> **[插入视频：给某个按钮添加 Prompt，生成的代码带有 onClick 处理函数]**

### 6. 存量代码增量更新（告别“一次性代码”）

设计稿改了，代码要重写？不存在的。
Sloth 提供了 **Diff 模式**：

- **算法模式**：如果原始代码也是 Sloth 生成的，我们会对比新旧 DSL，自动找出差异。
- **人工模式**：你可以手动圈出“哪里变了”。

Sloth 生成的 Prompt 是：“请理解新旧差异，仅生成变更补丁（Patch）”。这样生成的代码，是**补丁**，而不是**覆盖**。

> **[插入视频：展示代码增量更新的过程，Diff 对比]**

---

## 04. 实战效果：真的比手写好吗？

空口无凭，我们直接看代码的质量。

### 对比 1：代码语义化与复用

- **Sloth 转码**：识别了组件，使用了语义化的 Class 命名，甚至正确传递了 Props。

> **[建议插入图]**

### 对比 2：应对需求变更

场景：设计师将列表页的“价格”字段颜色改了，并增加了一个“特惠”标签。

- **Sloth 模式**：拦截器识别差异，AI 仅输出了几行 CSS 变更和一行 JSX 插入，原有的逻辑丝毫不动。

**结论**：在从 0 到 1 的构建上，Sloth 可能只比手写快 50%；但在 **从 1 到 1.1 的迭代维护** 上，效率提升是指数级的。

---

## 05. 写在最后的碎碎念

在 MCP 出现之前，我们也走过弯路。无论是节点清洗、图层合并，还是复杂的布局算法，人工规则总有覆盖不到的 Corner Case。

直到 Vibe Coding 概念兴起，Claude 3.5/4 的代码能力飞跃，我们意识到：**不要试图用算法去“翻译”设计稿，而应该用 AI 去“理解”设计稿。**

这也是我们为什么坚持做 **本地化 + MCP** 的原因：

1. **隐私安全**：借助 AI IDE 对 MCP 的支持，Sloth 的核心逻辑（设计稿解析、拦截、映射）**完全运行在你的本地 Node 环境**。你的设计稿、你的业务代码，从未离开过你的电脑。
2. **解耦**：Figma 只是开始。既然核心是“HTML 结构 -> 代码”，未来我们可以把输入源做得更宽。哪怕你扔给 \`Sloth MCP\` 一张截图、一个手绘草图，甚至一个 URL，只要能转换成我们的中间 DSL，就能接入这套拦截转码流程。

目前 \`Sloth MCP\` 并不完美，它依然依赖模型的能力和你的 Prompt 质量。但我们希望通过这套“人机协同”的架构，把 AI 的不确定性关在笼子里，让它老老实实地做那个“金牌辅助”。

未来，也许 AI 能一键搞定所有，但在那之前，\`Sloth MCP\` 愿意做那个最好用的“拐杖”。

---

**🛠️ AI 转码套件使用指导**

- **Figma 插件主页**：[Sloth D2C Plugin](https://www.figma.com/community/plugin/1497969094291954974/sloth-d2c)
- **MCP 工具安装文档**：[npm: sloth-d2c-mcp](https://www.npmjs.com/package/sloth-d2c-mcp)

欢迎大家试用并反馈 Bug，或者是单纯来聊聊你对 AI 转码的吐槽！
`;export{n as default};
//# sourceMappingURL=architecture-BI6erZrI.js.map
